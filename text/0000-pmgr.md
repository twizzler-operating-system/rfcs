- Feature Name: paging_and_persistence
- Start Date: 2022-06-03
- RFC PR: [twizzler-rfcs/rfcs#0000](https://github.com/twizzler-operating-system/rfcs/pull/0000)
- Twizzler Issue: [twizzler-operating-system/twizzler#0000](https://github.com/twizzler-operating-system/twizzler/issues/0000)

# Summary
[summary]: #summary

This RFC introduces the pager system, and specifies the core interaction between the pager system
and the kernel, and the interaction between the pager and userspace. The purpose of the pager is to
have a mechanism to allow for an object to exist outside the kernel's knowledge (e.g. on an SSD or out
on the network) and for that object to be brought into memory when needed. The kernel interacts with
the pager by submitting page and object info requests on a shared queue, and other applications may
interact with the pager via queues as well (to, e.g., submit synchronization requests or prefetching
hints).

# Motivation
[motivation]: #motivation

This mechanism is vital to support any amount of persistence or sharing, as we need some established
mechanism for the kernel to defer to userspace in the case that an object doesn't exist in memory
but does elsewhere. This also directly supports persistent objects, and combines directly with the
twizzler-nando crate. We expect the result to be, 1) a stable API for the kernel to defer to
userspace, 2) a system-level userspace service that handles those requests and can interact with
storage devices to load objects into memory (and sync them back to storage), and 3) a stable API for
other applications to submit requests to the pager.

# Guide-level explanation
[guide-level-explanation]: #guide-level-explanation

The *pager* is a userspace service that is tightly coupled with the kernel, and acts as a way for
the kernel to discover objects that it doesn't know about and to gain access to pages holding data
for those objects. One primary aspect of this is providing a way to use *stable storage* (any device
whose data persists) in Twizzler, with the pager moving pages back and forth between (e.g.) an SSD
and memory.

# Reference-level explanation
[reference-level-explanation]: #reference-level-explanation

The kernel expects the init program to communicate to it a pair of object IDs that are each Queue
objects---the *kernel request queue*, and the *pager request queue*. These objects allow for
communication between the kernel and userspace, where the userspace portion is expected to be a
binary program started by init that handles kernel paging requests.

The kernel pager request queue's submission and completion types are:

```{rust}
enum S {
    ObjectReq(ObjID),
    PageReq(ObjID, PageNumber),
    DramRel(usize),
    DramPages([u64; 16]),
    Evict(ObjID, PageNumber),
    TryEvict(usize),
    MemoryMap(MemoryMapInfo),
}

enum C {
    Success,
    ObjectInfo(ObjectInfo),
    PageInfo(PageInfo),
    DramPages([u64; 16]),
    EvictInfo(EvictInfo),
    Err(PagerReqError),
}
```

The kernel can ask the pager for information about an object that the kernel doesn't know about, and
it can also ask for information about a page for an object. The information returned by a request
for page information contains a physical address of a page of memory that the kernel can map in for
the object. The structures above may actually contain space for information for more than one page
to allow for batching. The purpose of DramPages, DramRel, DramReq, MemoryMap, and Evict* will be discussed below.

The pager's request queue has the following types:

```
enum S {
    PageInfo(PageInfo),
    ObjectInfo(ObjectInfo),
    DramReq(usize),
    DramPages([u64; 16]),
}

enum C {
    Success,
    DramPages([u64, 16]),
    Err(KernelReqError),
}
```

The pager can directly submit information about pages and objects to the kernel before the kernel
even asks for it, allowing for prefetching (possibly in the background, or application-driven). The
kernel can choose to ignore these prefetching requests.

## DRAM Management

To allow for the pager to implement some storage mechanism that does DMA transfer, the kernel allows
for DRAM-related requests over these queues. At any time the kernel can offer up unused pages of
DRAM for the pager to gain ownership over, and the pager can also issue a request for additional
pages. When requesting additional pages, the kernel is allowed to refuse if low on memory. The
kernel can also issue a request to the pager to release DRAM pages. The pager is allowed to refuse.
For this reason, the kernel should not pass ownership of all DRAM to the pager.

### Access to DRAM

Since the pager exists in userspace, it does not have access to the DRAM pages that are given to it
by the kernel. While in most operation, it does not need to read DRAM pages (the pager can submit
DMA commands without access to the memory), occasionally it might want to read page contents. To do
this, the pager can simply invent an object ID and submit PageInfo requests to the kernel to
temporarily map pages into accessable memory.

## Eviction

To support eviction, the kernel can inform the pager that a page must by written back to stable
storage. The pager must honor the kernel's command and must assume the page is dirty. However, this
is meant to be used as a last resort. The kernel can also submit a *request* that the pager free up
some number of pages. If a page returned to the kernel is dirty, the kernel will submit an
eviction notice for that page to inform the pager that it needs to write-back that page.

## Non-volatile Memory (NVM)

While NVM[^1] is not required for this system, it can be used as an accelerator for persistent
operations. To support this, the kernel can map NVM directly into the address space of the pager.
Once the queue are connected, the kernel will submit a sequence of MemoryMap commands to the pager
to announce to it the topology of the NVM in the system. After this, the pager may use the kaction
system call on it's VM handle to map the NVM into its address space whereever it likes. Device-level
access to the NVM can be handled via the device manager like any other device.

[^1]: Here, we're specifically talking about NVM that sits on the memory bus. Other forms that can
    be accessed (e.g.) via NVMe are treated more like an SSD.

## Connection to Applications

We plan to allow applications to connect to the pager and submit requests for synchronizing pages
back to stable storage. This involves applications connecting to the pager via a queue, allowing the
application to submit object IDs and page ranges for syncing. This will be supported via the
SyncRequest type, which can optionally act as a barrier or a flush to allow the pager to move requests around
and batch them for performance and still allow the application some control on ordering and forcing.

# Drawbacks
[drawbacks]: #drawbacks

Ultimately, the system needs a manager of stable storage and a mechanism to move object memory
safely to and from that storage.

# Rationale and alternatives
[rationale-and-alternatives]: #rationale-and-alternatives

The pager is designed to fit into userspace, because it cannot be easily implemented in-kernel. This
is because the drivers for devices that contain stable storage will be implemented in userspace, so
the pager (which sits above them) should be as well. As a result, most of the design decisions are
in-place to avoid the overheads of the kernel boundary crossings (escrow for DRAM pages, hinting,
etc.). The choice to bypass the object system for NVM is done for this same reason.

Another major component of this is the idea that a user application could submit syncing requests to
the pager in a more fine-grained way than "sync(2)" or "sync this object". The hope is to give
enough control to a transaction manager that could then efficiently sync only the pages that it
needs to to ensure failure-atomicity.

# Prior art
[prior-art]: #prior-art

This approach is similar to standard microkernel designs where the functionality of paging and
drivers for stable storage cannot be added to the kernel.

# Unresolved questions
[unresolved-questions]: #unresolved-questions

- The exact API between the kernel and the pager.
- The exact API between the pager and a user application.
- What features does the pager need to support to enable the implementation of the twizzler-nando
  crate?
- How does the pager operate, and how does it store object data on stable storage?

# Future possibilities
[future-possibilities]: #future-possibilities

TBD
