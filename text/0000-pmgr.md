- Feature Name: paging_and_persistence
- Start Date: 2022-06-03
- RFC PR: [twizzler-rfcs/rfcs#0002](https://github.com/twizzler-operating-system/rfcs/pull/0002)
- Twizzler Issue: [twizzler-operating-system/twizzler#0172](https://github.com/twizzler-operating-system/twizzler/issues/0172)

# Summary
[summary]: #summary

This RFC introduces the pager system, and specifies the core interaction between the pager system and the kernel. The
purpose of the pager is to have a mechanism to allow for an object to exist outside the kernel's knowledge (e.g. on an
SSD or out on the network) and for that object to be brought into memory when needed. The kernel interacts with the
pager by submitting page and object info requests on a shared queue.

In addition to specifying core pager behavior, this RFC outlines a set of phases in which the pager's functionality will
be expanded. In particular, we'll expand in the future on 1) pager-userspace interaction, 2) pager's interaction with
copy-from instructions and copy-on-write, 3) pager's interaction with a larger, network-enabled runtime, and 4) pager's
support and interaction for transactional operations on objects. We choose to expand on those in the future and not now
to keep this RFC smaller as it explores the core pager functionality.

# Motivation
[motivation]: #motivation

This mechanism is vital to support any amount of persistence or sharing, as we need some established
mechanism for the kernel to defer to userspace in the case that an object doesn't exist in memory
but does elsewhere. This also directly supports persistent objects, and combines directly with the
twizzler-nando crate. We expect the result to be, 1) a stable API for the kernel to defer to
userspace, 2) a system-level userspace service that handles those requests and can interact with
storage devices to load objects into memory (and sync them back to storage), and 3) a stable API for
other applications to submit requests to the pager (not included in this RFC).

# Guide-level explanation
[guide-level-explanation]: #guide-level-explanation

The *pager* provides 4 primary functions:

1. Managing memory pages provided by the kernel.
2. Filling those pages as needed to handle object page fetching commands from the kernel.
3. Ensuring persistence for modified pages according to restrictions set by userspace (e.g. on flush ordering).
4. Maintaining a cache of object memory pages, evicting as needed.

```
                           ┌───────────────┐        
                           │  Application  │        
                           └─────┬─▲───────┘        
                                 │ │                
┌────────────────────────────────┼─┼───────────────┐
│ Pager                          │ │Shared Queue   │
│     ┌─────────────────┬────────▼─┴────────┐      │
│     │ Persist Service │   User Interface  │      │
│     ├─────────────────┼───────────────────┤      │
│     │ Storage Service │  Kernel Interface │      │
│     ├─────────────────┼────────┬─▲────────┘      │
│     │   NVMe Driver   │        │ │Shared Queue   │
│     └─────────────────┘ ┌──────┼─┼───────────────┘
│                         │      │ │                
└─────────────────────────┘  ┌───▼─┴────┐           
                             │  Kernel  │           
                             └──────────┘           
```

The pager service is tightly coupled with the kernel, as it responds to any requests from the kernel to fetch
object pages from disk. On startup, the kernel establishes a shared queue over which it can send requests, and then
gives ownership of (likely, a majority of) free DRAM to the pager so that it can manage it as necessary. Once the kernel
starts its paging services, it will always forward page faults that it cannot immediately handle (ones that require allocating
a new page, or reading a page from stable storage) to the pager.

Applications, too, use a shared queue to communicate with the pager, established on application startup. These requests allow
applications to flush pages to stable storage, as well as discard, zero, and copy them.

Internally, the pager maintains a cache of object data pages along with an eviction strategy. When evicting an object page,
the pager requests the kernel to unmap that page. If the page is dirty, the pager must then write out the modified page to stable
storage, but _not_ in-place, i.e. the pager will never flush a page to stable storage object data unless explicitly told to.

# Reference-level explanation
[reference-level-explanation]: #reference-level-explanation

## Setup

The kernel expects the init program to communicate to it a pair of object IDs that are each Queue
objects---the *kernel request queue*, and the *pager request queue*. These objects allow for
communication between the kernel and userspace, where the userspace portion is expected to be a
binary program started by init that handles kernel paging requests.

This coordination on which objects to use for queues is done via the kernel using the `sys_new_handle` system call. The
init program calls this function twice to record first the kernel request queue, and second the pager request queue.
Once these queues' IDs are both told to the kernel, the kernel starts its internal paging mechanisms (implementation details not
outlined in this RFC).

## Kernel-Pager Queue Types

The kernel pager request queue's submission and completion types are:

```{rust}
enum KernelToPagerRequest {
    /// Provide ObjectInfo in response
    ObjectInfoReq(ObjID),
    /// Provide PageInfo in response
    PageDataReq(ObjID, [ObjectRange; NR_RANGES]),
    /// The kernel is giving ownership of these ranges to the pager
    DramPages([PhysRange; NR_PHYS_RANGES]),
    /// The kernel in informing the pager that this memory is being (or has already been) disconnected.
    Disconnect(PhysRange, DisconnectFlags),
}

enum KernelToPagerCompletion {
    Success,
    ObjectInfo(ObjectInfo),
    /// These should match the ObjectRanges from the request in structure.
    PageInfo([PhysRange; NR_RANGES]),
    Err(KernelToPagerReqError),
}

struct ObjectRange {
    start: u64,
    len: u64,
}
```

The pager's request queue has the following types:

```{rust}
enum PagerToKernelRequest {
    Evict(ObjID, [ObjectRange; NR_RANGES], EvictFlags),
    ObjectCopy(CopyCmd),
    Prefetch(ObjID, ObjectRange, PhysRange),
    ObjectInfo(ObjectInfo),
}

enum PagerToKernelCompletion {
    Success,
    EvictSuccess(EvictStats),
    Err(PagerToKernelReqError),
}

struct CopyCmd {
    src: ObjID,
    dst: ObjID,
    len: usize,
    src_start: usize,
    dst_start: usize,
}
```

The pager can directly submit information about pages and objects to the kernel before the kernel
even asks for it, allowing for prefetching (possibly in the background, or application-driven). The
kernel can choose to ignore these prefetching requests.

## Pager-User Queue Types
An application's pager request queue's submission and completion types are:

```{rust}
enum UserToPagerRequest {
    /// Provide ObjectInfo in response
    ObjectInfoReq(ObjID),
    /// Prefetch page data
    Prefetch(ObjID, [ObjectRange; NR_RANGES]),
    /// Sync modified pages
    Sync([SyncCmd; NR_SYNC_CMDS]),
    /// Discard modified pages
    Discard(ObjID, [ObjectRange; NR_RANGES]),
    /// Forget that pages are modified
    ForgetWrites(ObjID, [ObjectRange; NR_RANGES]),
    /// Copy object data
    ObjectCopy(CopyCmd),
}

enum UserToPagerCompletion {
    Success,
    ObjectInfo(ObjectInfo),
    Err(UserToPagerReqError),
}

struct SyncCmd {
    id: ObjID,
    ranges: [ObjectRange; NR_SYNC_RANGES],
}
```

## Memory Management

The kernel provides free DRAM to the pager on startup, transferring ownership of most of physical memory
to the pager. When transferring object data, the pager typically will not need to access the contents of any
given data page, instead submitting DMA requests with the address. However, it may occasionally need to read
physical pages, for example, when reading on-disk storage metadata. The pager can simply create a new object
the standard way and then back that object's data pages with any physical pages the pager needs to read.

The pager will track all DRAM pages that it owns, along with flags for dirty, accessed, mapped, and shared.
These bits are provided to the pager in two ways: as a bitmap from the kernel per memory region, and upon
successful eviction request from the pager (EvictSuccess variant in PagerToKernelCompletion). The bitmap
is written to by the kernel, and read by the pager. The pager can use the information in this bitmap to influence
eviction policy. After successful eviction from the kernel, the returned bits are used to determine current
status (to avoid time-of-check to time-of-use errors). 

### Physical Ranges

When communicating lists of pages back and forth, both sides use an array of `PhysRange`. A `PhysRange` defines
a contiguous physical memory region, made up of unused DRAM. At the end of the physical memory region, the kernel
provides a metadata region, containing a bitmap of flags per page in the region. This metadata region is located at
the end of the physical memory region to allow for maximum physical memory alignment at the start of the region (may
be important for DMA).

The `PhysRange` struct looks like: 

```{rust}
struct PhysRange {
    start: u64,
    nr_pages: u64,
    meta_nr_pages: u32,
    _flags: u32,
}
```

The `_flags` field is unused, and reserved to 0. The `meta_nr_pages` field defines the number of pages that the metadata for
this page range takes up.

### Eviction

If the pager runs out of managed memory pages, it will need to evict existing pages. This RFC does not detail the eviction strategy
nor the cache implementation. However, regardless of strategy, when a page is evicted the pager will not write the data back to disk
in-place, instead it will write to a swap area to as to avoid forcing a sync of object data. To assist in eviction strategy planning,
the bitmap per memory region provided by the kernel provides flags that can be used to affect a cost analysis of evicting a given page.

### Pinning Pager Memory

It is vital that the pager itself, (1) never swap out its own pages, and (2) ensure that any memory allocated to the pager is fully backed.
For (1), we can just track which objects the pager needs and disallow eviction for them, and for (2) the pager can use the Prefetch PagerToKernel request
to ensure any objects (like the heap) have backing memory pages.

## Kernel Requests

Above, we defined the request types. Here we'll elaborate on what they do.

### Object Info

When the kernel doesn't have knowledge of an object at all, the kernel asks the pager to provide initial knowledge via the ObjectInfo struct:

```{rust}
struct ObjectInfo {
    id: ObjID,
    lifetime: Lifetime,
    backing: BackingType,
}
```

This struct will likely grow over time.

### Object Page Data

When the kernel requests information about a page, it sends a set of `ObjectRange` structs for a given object ID. The
pager responds with a set of `PhysRange` structs. The pager's response does not need to fulfill the entire request, as
long as at least one page is filled (probably the first one). The kernel reads out physical pages, in order as specified
by the completion, and maps them in sequence into the object's page tree.

### Disconnects

Memory that is connected via some remote protocol, or hotplug memory, needs a way for the pager to be informed about possible
memory disconnection. The kernel informs the pager of which ranges will be disconnected, and the pager is then responsible for
moving memory to support that. If not possible, the pager can return an error.

### Prefetching

The pager can prefetch pages as it sees fit, without informing the kernel. Since it owns DRAM, it can fill it with anything from
stable storage that it likes. It can then inform the kernel that these pages could be used via the Prefetch command. It can similarly
pre-inform the kernel about objects that the pager knows about but the kernel does not.

The user can issue prefetch requests to the pager (which may go ignored).

## User Requests

Requests from user programs differ from kernel requests, since they are communicating for different reasons.

### Sync

The primary command userspace will send the pager is a sync command, which itself contains an object ID and a set of object ranges
to sync. These memory regions are then written back to stable storage in-place (unlike eviction, which does not write in-place).

### Barriers

In addition to the UserToPager enum that gets sent with every request, the pager also recieves a set of flags, which specify barrier rules.
For now, we'll implement this as two flags: one prevents previous requests from reoredering with this one (release semantics) and one prevents
future requests from reordering with this one. We disallow reoredering requests that set either of these bits with other requests that set either bit.
If both bits are set, this request acts as a full barrier.

### Discard

User programs may also discard dirty pages (e.g. when aborting a transaction). The pager evicts and replaces the dirty page with a fresh one. If, however,
the user program can easily return the contents to their unmodified state, discarding the pages is unneccessary. Thus user programs can also send a ForgetWrites
command that acts similarly to discard, but it just asserts to the pager that the page has returned to an unmodified state. This request is dangerous, as it can
lose writes, so should be used with care. It is not safe to issue ForgetWrites if concurrent updates to a given page are possible.

### Copy and Zeroing

When copying large amounts of object data, user programs can issue an ObjectCopy command. This command copies (or uses copy-on-write) to copy data from one object
to another at byte granularity. The pager is responsible for maintainting copy commands and their effects across power cycles.

# Drawbacks
[drawbacks]: #drawbacks

Ultimately, the system needs a manager of stable storage and a mechanism to move object memory
safely to and from that storage.

# Rationale and alternatives
[rationale-and-alternatives]: #rationale-and-alternatives

The pager is designed to fit into userspace, because it cannot be easily implemented in-kernel. This
is because the drivers for devices that contain stable storage will be implemented in userspace, so
the pager (which sits above them) should be as well. As a result, most of the design decisions are
in-place to avoid the overheads of the kernel boundary crossings (escrow for DRAM pages, hinting,
etc.). The choice to bypass the object system for NVM is done for this same reason.

Another major component of this is the idea that a user application could submit syncing requests to
the pager in a more fine-grained way than "sync(2)" or "sync this object". The hope is to give
enough control to a transaction manager that could then efficiently sync only the pages that it
needs to to ensure failure-atomicity.

However, syncing via the kernel is slow. Ideally, userspace would be able to request the pager sync without involving
the kernel at all. We plan to do this, see Future Possibilities. However, even with that system in-place, we want the
kernel to be able to submit sync requests. This is because it probably needs this support anyway, but we also need to
allow the kernel to send Sync requests to the pager on behalf of applications that may not be able to communicate with
the pager directly for some reason.

# Prior art
[prior-art]: #prior-art

This approach is similar to standard microkernel designs where the functionality of paging and
drivers for stable storage cannot be added to the kernel.

# Unresolved questions
[unresolved-questions]: #unresolved-questions

- What should the values of the constants A-I, above, be?
- What should the format of the on-stable-storage data be?
- Connection to larger runtime: we need to write a whole additional RFC about this.
- Currently we don't support good semantics for interacting with the copy-from API that the Twizzler kernel provides. A future RFC will expand on this.

- How will the kernel decide how much memory to give to the pager?
- Pager eviction strategy and cache design

# Future possibilities
[future-possibilities]: #future-possibilities

## Transactional support

We will need to expand this interface in several ways:

 1. Support ordering restrictions between kernel sync requests. This may be in the form of a barrier queue entry, or
    more complex semantics.
 2. Transactional support for object creation requires the pager be involved at object creation. This will require an
    expansion of the communication protocol.

## Connection to Applications

We plan to allow applications to connect to the pager and submit requests for synchronizing pages
back to stable storage. This involves applications connecting to the pager via a queue, allowing the
application to submit object IDs and page ranges for syncing. This will be supported via the
SyncRequest type, which can optionally act as a barrier or a flush to allow the pager to move requests around
and batch them for performance and still allow the application some control on ordering and forcing.

## Non-volatile Memory (NVM)

While NVM[^1] is not required for this system, it can be used as an accelerator for persistent
operations. To support this, the kernel can map NVM directly into the address space of the pager.
Once the queue are connected, the kernel will submit a sequence of MemoryMap commands to the pager
to announce to it the topology of the NVM in the system. After this, the pager may use the kaction
system call on it's VM handle to map the NVM into its address space whereever it likes. Device-level
access to the NVM can be handled via the device manager like any other device.

[^1]: Here, we're specifically talking about NVM that sits on the memory bus. Other forms that can
    be accessed (e.g.) via NVMe are treated more like an SSD.
